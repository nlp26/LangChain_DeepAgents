{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e43d0054",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_ollama import ChatOllama\n",
        "\n",
        "# print(\"Test with tag…\")\n",
        "# try:\n",
        "#     llm = ChatOllama(model=\"llama3.2:latest\", base_url=\"http://127.0.0.1:11434\", temperature=0)\n",
        "#     print(llm.invoke(\"Say hi (tag).\").content)\n",
        "# except Exception as e:\n",
        "#     print(\"Tag failed:\", e)\n",
        "\n",
        "# print(\"Test without tag…\")\n",
        "# try:\n",
        "#     llm = ChatOllama(model=\"llama3.2\", base_url=\"http://127.0.0.1:11434\", temperature=0)\n",
        "#     print(llm.invoke(\"Say hi (no tag).\").content)\n",
        "# except Exception as e:\n",
        "#     print(\"No-tag failed:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a845cf2",
      "metadata": {},
      "source": [
        "## Deep Agents 0.2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af49083a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# =============================\n",
        "# 0. SETUP: Mocks / Utilities\n",
        "# =============================\n",
        "\n",
        "@dataclass\n",
        "class Message:\n",
        "    role: str\n",
        "    content: str\n",
        "\n",
        "@dataclass\n",
        "class MockAgent:\n",
        "    name: str\n",
        "    memory: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    def _get_thread(self, config: Optional[Dict[str, Any]] = None) -> str:\n",
        "        cfg = (config or {}).get(\"configurable\", {})\n",
        "        return cfg.get(\"thread_id\", \"default-thread\")\n",
        "\n",
        "    def invoke(self, payload: Dict[str, Any], config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        thread = self._get_thread(config)\n",
        "        msgs: List[Message] = [Message(**m) if not isinstance(m, Message) else m for m in payload.get(\"messages\", [])]\n",
        "\n",
        "        # Super simple behavior & memory\n",
        "        last_user = next((m for m in reversed(msgs) if m.role == \"user\"), None)\n",
        "\n",
        "        # Memory store/recall\n",
        "        if last_user and \"favorite topic is\" in last_user.content.lower():\n",
        "            topic = last_user.content.split(\"is\", 1)[-1].strip().rstrip(\".\")\n",
        "            self.memory.setdefault(thread, {})[\"favorite_topic\"] = topic\n",
        "            reply = f\"Noted. I'll remember your favorite topic is {topic}.\"\n",
        "        elif last_user and \"what's my favorite topic\" in last_user.content.lower():\n",
        "            topic = self.memory.get(thread, {}).get(\"favorite_topic\", \"unknown\")\n",
        "            reply = f\"You told me your favorite topic is {topic}.\"\n",
        "        elif last_user and \"plan:\" in last_user.content.lower():\n",
        "            # Make a tiny plan\n",
        "            steps = [\"Research requirement\", \"Draft outline\", \"Implement\", \"Test\", \"Deliver\"]\n",
        "            reply = \"Plan generated:\\n\" + \"\\n\".join(f\"{i+1}. {s}\" for i, s in enumerate(steps))\n",
        "        elif last_user and \"search(\" in last_user.content.lower():\n",
        "            # mock search tool usage\n",
        "            reply = \"Search results: ['doc_a', 'doc_b', 'doc_c']\"\n",
        "        else:\n",
        "            reply = f\"Hello from {self.name}. You said: {last_user.content if last_user else '(no input)'}\"\n",
        "\n",
        "        result_msgs = msgs + [Message(role=\"assistant\", content=reply)]\n",
        "        return {\n",
        "            \"messages\": [m.__dict__ for m in result_msgs],\n",
        "            \"state\": {\"thread_id\": thread, \"memory\": self.memory.get(thread, {})}\n",
        "        }\n",
        "\n",
        "# Subagent container for demonstration\n",
        "@dataclass\n",
        "class MockCoordinator:\n",
        "    planner: MockAgent\n",
        "    researcher: MockAgent\n",
        "    implementer: MockAgent\n",
        "\n",
        "    def invoke(self, payload: Dict[str, Any], config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "        # very naive: planner -> researcher -> implementer\n",
        "        thread = (config or {}).get(\"configurable\", {}).get(\"thread_id\", \"default-thread\")\n",
        "        messages = payload.get(\"messages\", [])\n",
        "\n",
        "        p = self.planner.invoke({\"messages\": messages + [Message(role=\"user\", content=\"Plan: build a demo\").__dict__]}, config)\n",
        "        r = self.researcher.invoke({\"messages\": p[\"messages\"] + [Message(role=\"user\", content=\"search(query='demo')\").__dict__]}, config)\n",
        "        i = self.implementer.invoke({\"messages\": r[\"messages\"] + [Message(role=\"user\", content=\"Implement based on findings.\").__dict__]}, config)\n",
        "\n",
        "        return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fa8bb5a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 1. SETUP: Define a simple tool\n",
        "# ============================================\n",
        "\n",
        "def mock_search(query: str, max_results: int = 3) -> str:\n",
        "    \"\"\"Mock search tool that returns dummy results\"\"\"\n",
        "    return f\"Search results for '{query}': Found {max_results} relevant articles about {query}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9970604b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 2. CREATE AGENT: Test basic functionality\n",
        "# ============================================\n",
        "\n",
        "def test_basic_agent():\n",
        "    \"\"\"Test 1: Basic agent creation with default backend\"\"\"\n",
        "    print(\"\\n=== Test 1: Basic Deep Agent ===\")\n",
        "    \n",
        "    agent = create_deep_agent(\n",
        "        model=make_local_model(),\n",
        "        tools=[mock_search],\n",
        "        system_prompt=\"\"\"You are a research assistant. \n",
        "        Use the search tool to find information and write results to files.\"\"\"\n",
        "    )\n",
        "    \n",
        "    # Invoke with a simple task\n",
        "    result = agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Search for 'LangChain agents' and create a summary file.\"}]\n",
        "    })\n",
        "    \n",
        "    print(f\"✓ Agent created and invoked successfully\")\n",
        "    print(f\"✓ Total messages: {len(result['messages'])}\")\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ab1217d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 3. TEST SUBAGENTS: Validate subagent spawning\n",
        "# ============================================\n",
        "\n",
        "def test_subagents():\n",
        "    \"\"\"Test 2: Agent with specialized subagent\"\"\"\n",
        "    print(\"\\n=== Test 2: Agent with Subagents ===\")\n",
        "    \n",
        "    research_subagent = {\n",
        "        \"name\": \"deep-researcher\",\n",
        "        \"description\": \"Specialized agent for in-depth research tasks\",\n",
        "        \"system_prompt\": \"You are an expert researcher who provides detailed analysis.\",\n",
        "        \"tools\": [mock_search],\n",
        "        \"model\": make_local_model(),\n",
        "    }\n",
        "    \n",
        "    agent = create_deep_agent(\n",
        "        model=make_local_model(),\n",
        "        system_prompt=\"You are a supervisor. Delegate research tasks to the deep-researcher subagent.\",\n",
        "        subagents=[research_subagent]\n",
        "    )\n",
        "    \n",
        "    result = agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"Research LangGraph and provide a detailed report.\"}]\n",
        "    })\n",
        "    \n",
        "    print(f\"✓ Subagent configuration successful\")\n",
        "    print(f\"✓ Total messages: {len(result['messages'])}\")\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ce64c10f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 4. TEST BACKEND: Validate pluggable backend\n",
        "# ============================================\n",
        "\n",
        "def test_custom_backend():\n",
        "    \"\"\"Test 3: Agent with custom backend (new in 0.2)\"\"\"\n",
        "    print(\"\\n=== Test 3: Pluggable Backend (0.2 Feature) ===\")\n",
        "    \n",
        "    try:\n",
        "        from deepagents.backends.filesystem import FilesystemBackend\n",
        "        \n",
        "        backend = FilesystemBackend(root_dir=\"./agent_workspace\", virtual_mode=False)\n",
        "        agent = create_deep_agent(\n",
        "            model=make_local_model(),\n",
        "            tools=[mock_search],\n",
        "            system_prompt=\"You are a file management assistant.\",\n",
        "            backend=backend,\n",
        "        )\n",
        "        \n",
        "        print(\"✓ Custom backend configured successfully\")\n",
        "        return agent\n",
        "    except ImportError as e:\n",
        "        print(f\"⚠ Backend test skipped: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "28cb70be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 5. TEST PLANNING: Validate todo list tool\n",
        "# ============================================\n",
        "\n",
        "def test_planning_tool():\n",
        "    \"\"\"Test 4: Validate built‑in planning capabilities\"\"\"\n",
        "    print(\"\\n=== Test 4: Planning Tool ===\")\n",
        "\n",
        "    planning_subagent = {\n",
        "        \"name\": \"research-analyst\",\n",
        "        \"description\": \"Analyzes complex requests and drafts concise plans.\",\n",
        "        \"system_prompt\": (\n",
        "            \"Break the user goal into short, numbered action steps and return a bullet list.\"\n",
        "        ),\n",
        "        \"tools\": [mock_search],\n",
        "        \"model\": make_local_model(),\n",
        "    }\n",
        "\n",
        "    agent = create_deep_agent(\n",
        "        model=make_local_model(),\n",
        "        tools=[mock_search],\n",
        "        system_prompt=\"You must use the write_todos tool before starting complex tasks.\",\n",
        "        subagents=[planning_subagent],\n",
        "    )\n",
        "\n",
        "    result = agent.invoke({\n",
        "        \"messages\": [{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Create a multi-step plan to research and write a report on AI agents.\"\n",
        "        }]\n",
        "    })\n",
        "\n",
        "    print(\"✓ Planning tool available\")\n",
        "    print(f\"✓ Total messages: {len(result['messages'])}\")\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f871c008",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 6. TEST MEMORY: Validate checkpointing\n",
        "# ============================================\n",
        "\n",
        "def test_memory_persistence():\n",
        "    \"\"\"Test 5: Agent with memory/checkpointing\"\"\"\n",
        "    print(\"\\n=== Test 5: Memory Persistence ===\")\n",
        "    \n",
        "    checkpointer = MemorySaver()\n",
        "    \n",
        "    agent = create_deep_agent(\n",
        "        model=make_local_model(),\n",
        "        tools=[mock_search],\n",
        "        system_prompt=\"Remember previous conversations.\",\n",
        "        checkpointer=checkpointer\n",
        "    )\n",
        "    \n",
        "    config = {\"configurable\": {\"thread_id\": \"test-thread-1\"}}\n",
        "    \n",
        "    # First interaction\n",
        "    result1 = agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"My favorite topic is AI agents.\"}]\n",
        "    }, config)\n",
        "    \n",
        "    # Second interaction (should remember context)\n",
        "    result2 = agent.invoke({\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": \"What's my favorite topic?\"}]\n",
        "    }, config)\n",
        "    \n",
        "    print(f\"✓ Memory persistence configured\")\n",
        "    print(f\"✓ Thread maintained across invocations\")\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a1d29241",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "🧠 Deep Agents 0.2 Validation Suite\n",
            "============================================================\n",
            "\n",
            "=== Test 1: Basic Deep Agent ===\n",
            "✓ Agent created and invoked successfully\n",
            "✓ Total messages: 4\n",
            "\n",
            "=== Test 2: Agent with Subagents ===\n",
            "✓ Subagent configuration successful\n",
            "✓ Total messages: 2\n",
            "\n",
            "=== Test 3: Pluggable Backend (0.2 Feature) ===\n",
            "✓ Custom backend configured successfully\n",
            "\n",
            "=== Test 4: Planning Tool ===\n",
            "✓ Planning tool available\n",
            "✓ Total messages: 2\n",
            "\n",
            "=== Test 5: Memory Persistence ===\n",
            "✓ Memory persistence configured\n",
            "✓ Thread maintained across invocations\n",
            "\n",
            "============================================================\n",
            "✅ All validation tests completed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# 7. RUN ALL TESTS\n",
        "# ============================================\n",
        "\n",
        "def run_validation():\n",
        "    \"\"\"Run all validation tests\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🧠 Deep Agents 0.2 Validation Suite\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    try:\n",
        "        test_basic_agent()\n",
        "        test_subagents()\n",
        "        test_custom_backend()\n",
        "        test_planning_tool()\n",
        "        test_memory_persistence()\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ All validation tests completed successfully!\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Validation failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run validation suite\n",
        "    run_validation()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
